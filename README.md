<p align="center">
<h1 align="center">Adaptive Optimization Methods for Reasoning Boundaries: Dynamic Estimation and Multi-Agent Collaboration</h1>
</p>

<p align="center">
  	<a href="https://img.shields.io/badge/version-v0.1.0-blue">
      <img alt="version" src="https://img.shields.io/badge/version-v0.1.0-blue?color=FF8000?color=009922" />
    </a>
    <a >
       <img alt="PRs-Welcome" src="https://img.shields.io/badge/PRs-Welcome-blue" />
  	</a>
    <br />
</p>

## ğŸ” Overview

This repository contains the implementation of three novel approaches to optimize reasoning within model boundaries:

1. **Advanced Minimum Acceptable Reasoning Paths (A-MARP)**: Extends the original MARP with adaptive step calibration, difficulty-aware decomposition, and contextual boundary awareness.

2. **Dynamic Boundary Estimation (DBE)**: A real-time method that probes model capabilities during interaction, adaptively estimating reasoning boundaries and adjusting prompting strategies accordingly.

3. **Multi-Agent Reasoning Collaboration (MARC)**: A framework leveraging specialized agents with complementary reasoning strengths, implementing task-specific delegation and consensus mechanisms.

## ğŸ“Š Datasets

We evaluate our methods on seven reasoning datasets across multiple domains:

- **BIGGSM**: Extended version of the dataset containing complex arithmetic problems with varying calculation amounts.
- **GSM8K**: Grade school math word problems requiring multi-step reasoning.
- **MATH**: Advanced mathematics problems across various topics.
- **MultiArith**: Elementary arithmetic word problems.
- **HotpotQA**: Multi-hop question answering requiring reasoning across documents.
- **StrategyQA**: Questions requiring implicit multi-step reasoning and strategy.
- **MGSM**: Multilingual mathematical reasoning dataset.

### Dataset Preparation

```bash
# Clone the repository
git clone https://github.com/Barryshen1/adaptive-reasoning-boundaries.git
cd adaptive-reasoning-boundaries

# Install dependencies
pip install -r requirements.txt

# Download datasets
python scripts/download_datasets.py
```

## ğŸ”§ Installation

```bash
# Install dependencies
pip install -r requirements.txt
```

## ğŸš€ Running Experiments

### A-MARP

```bash
python run_amarp.py --dataset GSM8K \
                    --model gpt-4 \
                    --alpha 0.15 \
                    --beta 0.08 \
                    --c_max 5 \
                    --output_dir results/amarp
```

### DBE

```bash
python run_dbe.py --dataset BIGGSM \
                 --model gpt-4 \
                 --gamma 0.12 \
                 --probe_frequency 5 \
                 --probe_size 7 \
                 --output_dir results/dbe
```

### MARC

```bash
python run_marc.py --dataset HotpotQA \
                  --models gpt-4,claude-3.5-sonnet,llama-3.1-70b \
                  --agent_roles planner,calculator,verifier,integrator \
                  --communication_rounds 5 \
                  --output_dir results/marc
```

### Running All Methods

```bash
python run_all.py --dataset GSM8K \
                 --model gpt-4 \
                 --output_dir results/all
```

## ğŸ“ˆ Evaluation

To evaluate the performance of our methods:

```bash
python evaluate.py --results_dir results/amarp \
                   --metrics accuracy,boundary_error,token_efficiency \
                   --visualize
```

For ablation studies:

```bash
python ablation.py --method amarp \
                   --components adaptive_step,difficulty_aware,contextual_boundary,memory_augmented \
                   --dataset BIGGSM \
                   --model gpt-4
```

## ğŸ“Š Analysis

### Visualization

Generate performance comparison plots:

```bash
python visualize.py --results_dir results \
                    --plot boundary_performance,cross_model,difficulty_analysis \
                    --output_dir figures
```

### Reports

Generate detailed analysis reports:

```bash
python generate_report.py --results_dir results \
                          --output_file report.md
```

## ğŸ§ª Experimental Results

Our methods consistently outperform baseline approaches across all datasets:

- A-MARP provides a XX% average improvement over the original MARP.
- DBE demonstrates adaptive capability with up to XX% improvement after 10 interactions.
- MARC shows the largest improvement, with a XX% gain on BIGGSM and XX% on HotpotQA compared to standard CoT.

Key strengths of our approaches:

- A-MARP is particularly effective in the Partially Feasible Reasoning Boundary (PFRB) regions.
- DBE's boundary estimation significantly improves with more interactions, demonstrating its learning capability.
- MARC leverages complementary reasoning strengths, with cross-model teams showing the best performance.

## ğŸ§© Project Structure

```
adaptive-reasoning-boundaries/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ methods/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ a_marp.py
â”‚   â”œâ”€â”€ dbe.py
â”‚   â””â”€â”€ marc.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ loaders/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ dataset_loaders.py
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â”œâ”€â”€ a_marp_config.py
â”‚   â”‚   â”œâ”€â”€ dbe_config.py
â”‚   â”‚   â””â”€â”€ marc_config.py
â”‚   â””â”€â”€ results/
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data.py
â”‚   â”œâ”€â”€ tools.py
â”‚   â””â”€â”€ request_tool.py
â”œâ”€â”€ run_experiments.py
â””â”€â”€ analyze_results.py
```

## ğŸ“š Citation

If you find our work useful, please consider citing:

```bibtex
@inproceedings{author2025adaptive,
    title = "Adaptive Optimization Methods for Reasoning Boundaries: Dynamic Estimation and Multi-Agent Collaboration",
    author = "Author, Anonymous",
    booktitle = "Proc. of NeurIPS",
    year = "2025",
}
```

## ğŸ”— Related Work

Our work builds directly on the Reasoning Boundary Framework (RBF):

```bibtex
@inproceedings{chen-etal-2024-rg,
    title = "Unlocking the Boundaries of Thought: A Reasoning Granularity Framework to Quantify and Optimize Chain-of-Thought",
    author = "Chen, Qiguang  and
      Qin, Libo  and
      Jiaqi, Wang  and
      Jinxuan, Zhou  and
      Che, Wanxiang",
    booktitle = "Proc. of NeurIPS",
    year = "2024",
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“§ Contact

For questions or feedback, please create GitHub issues or contact the authors.

---

## Acknowledgments


